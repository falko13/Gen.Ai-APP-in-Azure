{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -U datasets==2.17.0\n",
        "\n",
        "%pip install --upgrade pip\n",
        "%pip install --disable-pip-version-check \\\n",
        "    torch==1.13.1 \\\n",
        "    torchdata==0.5.1 --quiet\n",
        "\n",
        "%pip install \\\n",
        "    transformers==4.27.2 \\\n",
        "    evaluate==0.4.0 \\\n",
        "    rouge_score==0.1.2 \\\n",
        "    loralib==0.1.1 \\\n",
        "    peft==0.3.0 --quiet\n",
        "\n",
        "    \n",
        "# Installing the Reinforcement Learning library directly from github.\n",
        "# %pip install git+https://github.com/lvwerra/trl.git@25fa1bd  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: datasets==2.17.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.17.0)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (3.12.2)\nRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (1.25.0)\nRequirement already satisfied: pyarrow>=12.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (12.0.1)\nRequirement already satisfied: pyarrow-hotfix in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (0.3.8)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (4.65.0)\nRequirement already satisfied: xxhash in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (3.4.1)\nRequirement already satisfied: multiprocess in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (0.70.16)\nRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (2023.6.0)\nRequirement already satisfied: aiohttp in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (3.9.3)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (0.20.3)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (23.0)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets==2.17.0) (6.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets==2.17.0) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets==2.17.0) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets==2.17.0) (1.3.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets==2.17.0) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets==2.17.0) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets==2.17.0) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets==2.17.0) (4.6.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.0) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.0) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->datasets==2.17.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->datasets==2.17.0) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->datasets==2.17.0) (2023.3)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.17.0) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: pip in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (23.1.2)\nCollecting pip\n  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.1.2\n    Uninstalling pip-23.1.2:\n      Successfully uninstalled pip-23.1.2\nSuccessfully installed pip-24.0\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "    \n",
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1709189767569
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = '../src'\n",
        "output_folder = '../output'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "../src folder created\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1709189767968
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ../src/conda-env.yml\n",
        "name: basic-env-cpu\n",
        "channels:\n",
        "  - conda-forge\n",
        "  - defaults\n",
        "dependencies:\n",
        "  - pip\n",
        "  - pip:\n",
        "    - torch==1.13.1\n",
        "    - rouge_score==0.1.2\n",
        "  - python=3.10.11\n",
        "  - datasets==2.17.0\n",
        "  - torchdata==0.5.1\n",
        "  - transformers==4.27.2\n",
        "  - evaluate==0.4.0\n",
        "  - loralib==0.1.1\n",
        "  - peft==0.3.0\n",
        "  - mlflow"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create new environment using base Docker image and conda specs.\n",
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env_docker_conda = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-1.13-cuda11.7:latest\",\n",
        "    conda_file=\"../src/conda-env.yml\",\n",
        "    name=\"docker-image-llm\",\n",
        "    description=\"llm from docker\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env_docker_conda)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/sentiment_prediction.py\n",
        "import mlflow\n",
        "import argparse\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "def predict_sentiment(dialogue, output_path, model_name='google/flan-t5-base'):\n",
        "    # Initialize tokeniazer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "    # Constructing a 5-shot prompt with examples\n",
        "    start_prompt = '''Provide Sentiment for the following comment/conversation (possible sentiments: Positive, Negative, Neutral):\n",
        "\n",
        "    Comment: \"I love sunny days, they make me feel so happy!\"\n",
        "    Sentiment: Positive\n",
        "\n",
        "    Comment: \"This is the worst experience of my life, I'm so disappointed.\"\n",
        "    Sentiment: Negative\n",
        "\n",
        "    Comment: \"I'm not sure how I feel about this new policy. It might be good or bad.\"\n",
        "    Sentiment: Neutral\n",
        "\n",
        "    Comment: \"The service at this restaurant was fantastic, best dinner ever!\"\n",
        "    Sentiment: Positive\n",
        "\n",
        "    Comment: \"I waited for an hour and my order was still wrong.\"\n",
        "    Sentiment: Negative\n",
        "\n",
        "    Comment: '''\n",
        "    \n",
        "    end_prompt = '\\nSentiment: '\n",
        "    \n",
        "    # Construct the full prompt with the user-provided dialogue\n",
        "    prompt = start_prompt + '\"' + dialogue + '\"' + end_prompt \n",
        "\n",
        "    # Tokenize input dialogue\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate prediction\n",
        "    output = model.generate(inputs['input_ids'], max_new_tokens=50)\n",
        "    \n",
        "    # Decode and print the prediction\n",
        "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    \n",
        "    # Write the predicted sentiment to the specified output file\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write('Text: ' + dialogue + '\\nPredicted Sentiment: ' + decoded_output + '\\n')\n",
        "\n",
        "def main():\n",
        "    # enable autologging\n",
        "    mlflow.autolog()\n",
        "    \n",
        "    parser = argparse.ArgumentParser(description=\"Predict sentiment from input dialogue\")\n",
        "    parser.add_argument(\"--dialogue\", type=str, required=True, help=\"Input dialogue for sentiment prediction\")\n",
        "    parser.add_argument(\"--output\", type=str, required=True, help=\"Output file path for sentiment prediction\")\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Predict sentiment and write to output\n",
        "    predict_sentiment(args.dialogue, args.output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ../src/sentiment_prediction.py\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test script\n",
        "#!python $script_folder/sentiment_prediction.py --dialogue \"I love this book!\" --output $output_folder\"/output.txt\"\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2024/02/24 06:28:48 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of transformers. If you encounter errors during autologging, try upgrading / downgrading transformers to a supported version, or try upgrading MLflow.\n2024-02-24 06:28:48.480926: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-02-24 06:28:52.141555: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2024-02-24 06:28:53.196121: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2024-02-24 06:28:53.196169: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2024-02-24 06:29:01.806885: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2024-02-24 06:29:01.807156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2024-02-24 06:29:01.807178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n2024/02/24 06:29:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n2024/02/24 06:29:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n2024/02/24 06:29:14 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\nDownloading: 100%|█████████████████████████| 2.48k/2.48k [00:00<00:00, 12.4MB/s]\nDownloading: 100%|███████████████████████████| 773k/773k [00:00<00:00, 1.97MB/s]\nDownloading: 100%|█████████████████████████| 2.31M/2.31M [00:00<00:00, 12.0MB/s]\nDownloading: 100%|█████████████████████████| 2.15k/2.15k [00:00<00:00, 12.9MB/s]\nDownloading: 100%|█████████████████████████| 1.37k/1.37k [00:00<00:00, 8.36MB/s]\nDownloading: 100%|███████████████████████████| 945M/945M [00:28<00:00, 34.3MB/s]\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import ComputeInstance\n",
        "\n",
        "\n",
        "ci = ComputeInstance(\n",
        "    name=\"compute-instance\", \n",
        "    size=\"Standard_E4ds_v4\"\n",
        ")\n",
        "ml_client.begin_create_or_update(ci).result()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ../sentiment_prediction.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: sentiment_prediction_merged\n",
        "display_name: Sentiment Prediction with Integrated Tokenization\n",
        "version: 3\n",
        "type: command\n",
        "inputs:\n",
        "  dialogue: \n",
        "    type: string\n",
        "outputs:\n",
        "  sentiment_output:\n",
        "    type: uri_file\n",
        "code: ./src\n",
        "environment: azureml:docker-image-llm@latest\n",
        "compute: azureml:cpu-cluster\n",
        "command: >-\n",
        "  python sentiment_prediction.py \n",
        "  --dialogue ${{inputs.dialogue}}\n",
        "  --output ${{outputs.sentiment_output}}\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ../sentiment_prediction.yml\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "\n",
        "@pipeline()\n",
        "def sentiment_prediction(pipeline_job_input):\n",
        "    sentiment = predict_sentiment_segment(dialogue=pipeline_job_input)\n",
        "\n",
        "    return {\n",
        "        \"pipeline_job_predict_sentiment_data\": sentiment.outputs.sentiment_output,\n",
        "        \n",
        "    }\n",
        "\n",
        "# Example usage with a direct string input for the dialogue\n",
        "pipeline_job = sentiment_prediction(pipeline_job_input='\"Movie is rathet bad!\"')\n",
        "pipeline_job.settings.default_compute = \"compute-instance\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "parent_dir = \"\"\n",
        "\n",
        "predict_sentiment_segment = load_component(source=parent_dir + \"../sentiment_prediction.yml\")\n",
        "\n",
        "# register component\n",
        "prep = ml_client.components.create_or_update(predict_sentiment_segment, version='6')"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1709015832518
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "\n",
        "@pipeline()\n",
        "def sentiment_prediction(pipeline_job_input):\n",
        "    sentiment = predict_sentiment_segment(dialogue=pipeline_job_input)\n",
        "\n",
        "    return {\n",
        "        \"pipeline_job_predict_sentiment_data\": sentiment.outputs.sentiment_output,\n",
        "        \n",
        "    }\n",
        "\n",
        "# Example usage with a direct string input for the dialogue\n",
        "pipeline_job = sentiment_prediction(pipeline_job_input='\"Movie is rathet bad!\"')\n",
        "pipeline_job.settings.default_compute = \"compute-instance\""
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709015835758
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submit job to workspace\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=\"sentiment_prediction\"\n",
        ")\n",
        "pipeline_job"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "PipelineJob({'inputs': {'pipeline_job_input': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x7f300ffbf5b0>}, 'outputs': {'pipeline_job_predict_sentiment_data': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x7f300ffbf580>}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-instance/code/Users/opanasenko2084/Gen.Ai-APP-in-Azure/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f300ffbf4f0>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'sentiment_prediction', 'is_deterministic': None, 'inputs': {'pipeline_job_input': {}}, 'outputs': {'pipeline_job_predict_sentiment_data': {}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'sentiment': Command({'parameters': {}, 'init': False, 'name': 'sentiment', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-instance/code/Users/opanasenko2084/Gen.Ai-APP-in-Azure/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f300ff25240>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'dialogue': '${{parent.inputs.pipeline_job_input}}'}, 'job_outputs': {'sentiment_output': '${{parent.outputs.pipeline_job_predict_sentiment_data}}'}, 'inputs': {'dialogue': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f300ffbf760>}, 'outputs': {'sentiment_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f301c116260>}, 'component': 'azureml_anonymous:2d227dc3-faa8-4948-bcf6-19c46f4b92ab', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '115284f9-9688-4eec-88f1-bd80390b9a93', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False})}, 'job_types': {'command': 1}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 1}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'busy_chicken_qw3fty2g06', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/falko13/Gen.Ai-APP-in-Azure.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': 'c8134dbc4eadd7865a07d95bc43e9914f7c8c1f8', 'azureml.git.dirty': 'True', 'azureml.DevPlatv2': 'true', 'azureml.DatasetAccessMode': 'Asset', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{\"pipeline_job_input\":\"\\\\\"Movie is rathet bad!\\\\\"\"}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.enforceRerun': 'False', 'azureml.defaultComputeName': 'compute-instance', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/71dd2dd9-4027-4b07-a6aa-e98b8b31e8cc/resourceGroups/cloud-shell-storage-southeastasia/providers/Microsoft.MachineLearningServices/workspaces/oksana_ml/jobs/busy_chicken_qw3fty2g06', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-instance/code/Users/opanasenko2084/Gen.Ai-APP-in-Azure/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f300ffbf550>, 'serialize': <msrest.serialization.Serializer object at 0x7f300ffbf220>, 'display_name': 'sentiment_prediction', 'experiment_name': 'sentiment_prediction', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://australiasoutheast.api.azureml.ms/mlflow/v1.0/subscriptions/71dd2dd9-4027-4b07-a6aa-e98b8b31e8cc/resourceGroups/cloud-shell-storage-southeastasia/providers/Microsoft.MachineLearningServices/workspaces/oksana_ml?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/busy_chicken_qw3fty2g06?wsid=/subscriptions/71dd2dd9-4027-4b07-a6aa-e98b8b31e8cc/resourcegroups/cloud-shell-storage-southeastasia/workspaces/oksana_ml&tid=df64ec22-8387-4f67-874d-a8321645e4ba', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>sentiment_prediction</td><td>busy_chicken_qw3fty2g06</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/busy_chicken_qw3fty2g06?wsid=/subscriptions/71dd2dd9-4027-4b07-a6aa-e98b8b31e8cc/resourcegroups/cloud-shell-storage-southeastasia/workspaces/oksana_ml&amp;tid=df64ec22-8387-4f67-874d-a8321645e4ba\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709015843005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #CLI2 version of creating component and pipeline\n",
        "# !az extension add --name ml -y\n",
        "# output = %sx az ml component list \\\n",
        "#         --resource-group \"cloud-shell-storage-southeastasia\" \\\n",
        "#         --workspace-name \"oksana_ml\"\n",
        "# print(output)\n",
        "# !az ml component create --file ../sentiment_prediction.yml\n",
        "# !az ml job create --file ../pipeline_sentiment_prediction.yml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Script to register the 'google/flan-t5-base' model for sentiment analysis with MLflow and Azure ML for future online inference\n",
        "\n",
        "# Importing necessary libraries for Azure ML, MLflow, and model loading\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import Model\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import mlflow\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "def register_model_with_mlflow(model_name='google/flan-t5-base', model_save_path='saved_models/flan_t5_base'):\n",
        "    \"\"\"\n",
        "    Load a pre-trained model and tokenizer from Hugging Face, save them locally,\n",
        "    and register the model with MLflow for tracking and version control.\n",
        "    \n",
        "    Parameters:\n",
        "    - model_name (str): Identifier for the pre-trained model on Hugging Face.\n",
        "    - model_save_path (str): Local directory path for saving the model and tokenizer.\n",
        "    \n",
        "    Returns:\n",
        "    - mlflow_model_name (str): The name of the model registered in MLflow, adjusted for compatibility.\n",
        "    \"\"\"\n",
        "    # Adjusting model_name for MLflow compatibility (replacing '/' with '_')\n",
        "    mlflow_model_name = model_name.replace('/', '_')\n",
        "\n",
        "    # Loading the tokenizer and model from Hugging Face Transformers\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "    \n",
        "    # Saving the tokenizer and model locally\n",
        "    tokenizer.save_pretrained(model_save_path)\n",
        "    model.save_pretrained(model_save_path)\n",
        "    \n",
        "    # Logging the model to MLflow with the adjusted name\n",
        "    mlflow.pytorch.log_model(pytorch_model=model, artifact_path=\"models\", registered_model_name=mlflow_model_name)\n",
        "    \n",
        "    return mlflow_model_name\n",
        "\n",
        "def main():\n",
        "    # Setting up MLflow: Configuring the tracking URI and experiment name\n",
        "    mlflow.set_tracking_uri(\"your_mlflow_tracking_uri\")  # Replace with your actual MLflow tracking URI\n",
        "    mlflow.set_experiment(\"ModelRegistrationExperiment\")\n",
        "\n",
        "    # Starting an MLflow run to log model information\n",
        "    with mlflow.start_run():\n",
        "        mlflow_model_name = register_model_with_mlflow()\n",
        "\n",
        "    # Fetching the latest run from the experiment for artifact URI\n",
        "    experiment = mlflow.get_experiment_by_name(\"ModelRegistrationExperiment\")\n",
        "    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
        "    latest_run_id = runs.iloc[0]['run_id']  # Assuming the latest run contains the relevant model\n",
        "\n",
        "    # Extracting the model artifact URI from the latest run information\n",
        "    run_info = mlflow.get_run(latest_run_id)\n",
        "    model_artifact_uri = run_info.info.artifact_uri + \"/models\"\n",
        "\n",
        "\n",
        "    # Defining Azure ML model metadata for registration\n",
        "    azure_model = Model(\n",
        "        name=mlflow_model_name,  # Name of the model in Azure ML registry\n",
        "        description=\"Pre-trained sentiment analysis model registered via MLflow.\",\n",
        "        # type=\"mlflow_model\",  # Model type indicating it's tracked by MLflow\n",
        "        type=AssetTypes.MLFLOW_MODEL,\n",
        "        path=model_artifact_uri,  # Path to the model artifact for registration\n",
        "        version=\"4\"  # Model version\n",
        "    )\n",
        "    \n",
        "    # Registering the model in Azure ML\n",
        "    registered_model = ml_client.models.create_or_update(azure_model)\n",
        "    print(f\"Model registered successfully in Azure ML: {registered_model.name}, Version: {registered_model.version}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n  warnings.warn(\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\nRegistered model 'google_flan-t5-base' already exists. Creating a new version of this model...\n2024/02/28 08:46:07 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: google_flan-t5-base, version 12\nCreated version '12' of model 'google_flan-t5-base'.\nYour file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n\nExample: azcopy copy '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-instance/code/Users/opanasenko2084/Gen.Ai-APP-in-Azure/notebooks/your_mlflow_tracking_uri/425685742346182231/c4cee08203d24dbb8228e09e5b9eba9f/artifacts/models' 'https://oksanaml7538443157.blob.core.windows.net/azureml-blobstore-ce49baec-5e26-4e4d-9649-a752220012af/LocalUpload/010073a314b62c74cc0f51f69afdb924/models' \n\nSee https://docs.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n\u001b[32mUploading models (990.48 MBs): 100%|██████████| 990481691/990481691 [00:14<00:00, 70252039.26it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model registered successfully in Azure ML: google_flan-t5-base, Version: 4\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709110003197
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define and create an endpoint\n",
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "import datetime\n",
        "\n",
        "online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"Online endpoint for sentiment extraction\",\n",
        "    auth_mode=\"key\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709189873276
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-02290657909631.australiasoutheast.inference.ml.azure.com/score', 'openapi_uri': 'https://endpoint-02290657909631.australiasoutheast.inference.ml.azure.com/swagger.json', 'name': 'endpoint-02290657909631', 'description': 'Online endpoint for sentiment extraction', 'tags': {}, 'properties': {'azureml.onlineendpointid': '/subscriptions/71dd2dd9-4027-4b07-a6aa-e98b8b31e8cc/resourcegroups/cloud-shell-storage-southeastasia/providers/microsoft.machinelearningservices/workspaces/oksana_ml/onlineendpoints/endpoint-02290657909631', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/71dd2dd9-4027-4b07-a6aa-e98b8b31e8cc/providers/Microsoft.MachineLearningServices/locations/australiasoutheast/mfeOperationsStatus/oe:ce49baec-5e26-4e4d-9649-a752220012af:b0f9cdd3-a918-48d8-898d-ffe73bdb7af2?api-version=2022-02-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/71dd2dd9-4027-4b07-a6aa-e98b8b31e8cc/resourceGroups/cloud-shell-storage-southeastasia/providers/Microsoft.MachineLearningServices/workspaces/oksana_ml/onlineEndpoints/endpoint-02290657909631', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-instance/code/Users/opanasenko2084/Gen.Ai-APP-in-Azure/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fcc6cb23520>, 'auth_mode': 'key', 'location': 'australiasoutheast', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7fcc6cb23a90>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709189981284
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configure the deployment\n",
        "from azure.ai.ml.entities import Model, ManagedOnlineDeployment\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# create a blue deployment\n",
        "model = Model(\n",
        "    path=\"azureml://locations/australiasoutheast/workspaces/ce49baec-5e26-4e4d-9649-a752220012af/models/google_flan-t5-base/versions/4\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    description=\"sentiment extraction mlflow model\",\n",
        ")\n",
        "\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_F4s_v2\",\n",
        "    instance_count=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create deployment\n",
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "name": "ml.geospatial.interactive",
        "_defaultOrder": 20,
        "hideHardwareSpecs": true,
        "vcpuNum": 0,
        "_isFastLaunch": false,
        "gpuNum": 0,
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "category": "General purpose",
        "memoryGiB": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 57,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.trn1.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 58,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.trn1.32xlarge",
        "vcpuNum": 128
      },
      {
        "_defaultOrder": 59,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.trn1n.32xlarge",
        "vcpuNum": 128
      }
    ],
    "instance_type": "ml.m5.2xlarge",
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}